{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Spark Example\n",
    "\n",
    "Almond comes with a Spark integration module called *almond-spark*, which allows you to connect to a Spark cluster and\n",
    "to run Spark calculations interactively from a Jupyter notebook.\n",
    "\n",
    "It is based on [ammonite-spark](https://github.com/alexarchambault/ammonite-spark), adding Jupyter specific features\n",
    "such as progress bars and cancellation for running Spark computations.\n",
    "\n",
    "*ammonite-spark* handles loading Spark in a clever way, and does not rely on a specific Spark distribution.\n",
    "Because of that, you can use it with any Spark 2.x version.\n",
    "The only limitation is that the Scala version of Spark and the running Almond kernel must match, so make sure your\n",
    "kernel uses the same Scala version as your Spark cluster.\n",
    "Spark 2.0.x - 2.3.x requires Scala 2.11. Spark 2.4.x supports both Scala 2.11 and 2.12.\n",
    "\n",
    "For more information, see the [README](https://github.com/alexarchambault/ammonite-spark/blob/master/README.md) of ammonite-spark.\n",
    "\n",
    "To use it, just import Spark 2.x, the *almond-spark* dependency will be added automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://repo1.maven.org/maven2/sh/almond/almond-spark_2.11/0.6.0/almond-spark_2.11-0.6.0.pom\n",
      "Downloading https://repo1.maven.org/maven2/sh/almond/almond-spark_2.11/0.6.0/almond-spark_2.11-0.6.0.pom.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/sh/almond/almond-spark_2.11/0.6.0/almond-spark_2.11-0.6.0.pom.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/sh/almond/almond-spark_2.11/0.6.0/almond-spark_2.11-0.6.0.pom\n",
      "Downloading https://repo1.maven.org/maven2/sh/almond/ammonite-spark_2.11/0.5.0/ammonite-spark_2.11-0.5.0.pom\n",
      "Downloading https://repo1.maven.org/maven2/sh/almond/ammonite-spark_2.11/0.5.0/ammonite-spark_2.11-0.5.0.pom.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/sh/almond/ammonite-spark_2.11/0.5.0/ammonite-spark_2.11-0.5.0.pom\n",
      "Downloaded https://repo1.maven.org/maven2/sh/almond/ammonite-spark_2.11/0.5.0/ammonite-spark_2.11-0.5.0.pom.sha1\n",
      "Downloading https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-server/9.4.19.v20190610/jetty-server-9.4.19.v20190610.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-server/9.4.19.v20190610/jetty-server-9.4.19.v20190610.pom.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-server/9.4.19.v20190610/jetty-server-9.4.19.v20190610.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-server/9.4.19.v20190610/jetty-server-9.4.19.v20190610.pom.sha1\n",
      "Downloading https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-project/9.4.19.v20190610/jetty-project-9.4.19.v20190610.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-project/9.4.19.v20190610/jetty-project-9.4.19.v20190610.pom.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-project/9.4.19.v20190610/jetty-project-9.4.19.v20190610.pom.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-project/9.4.19.v20190610/jetty-project-9.4.19.v20190610.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-http/9.4.19.v20190610/jetty-http-9.4.19.v20190610.pom.sha1\n",
      "Downloading https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-io/9.4.19.v20190610/jetty-io-9.4.19.v20190610.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-io/9.4.19.v20190610/jetty-io-9.4.19.v20190610.pom.sha1\n",
      "Downloading https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-http/9.4.19.v20190610/jetty-http-9.4.19.v20190610.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-io/9.4.19.v20190610/jetty-io-9.4.19.v20190610.pom.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-http/9.4.19.v20190610/jetty-http-9.4.19.v20190610.pom.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-io/9.4.19.v20190610/jetty-io-9.4.19.v20190610.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-http/9.4.19.v20190610/jetty-http-9.4.19.v20190610.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-util/9.4.19.v20190610/jetty-util-9.4.19.v20190610.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-util/9.4.19.v20190610/jetty-util-9.4.19.v20190610.pom.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-util/9.4.19.v20190610/jetty-util-9.4.19.v20190610.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-util/9.4.19.v20190610/jetty-util-9.4.19.v20190610.pom.sha1\n",
      "Downloading https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-server/9.4.19.v20190610/jetty-server-9.4.19.v20190610.jar.sha1\n",
      "Downloading https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-server/9.4.19.v20190610/jetty-server-9.4.19.v20190610.jar\n",
      "Downloading https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-util/9.4.19.v20190610/jetty-util-9.4.19.v20190610.jar.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-server/9.4.19.v20190610/jetty-server-9.4.19.v20190610.jar.sha1\n",
      "Downloading https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-io/9.4.19.v20190610/jetty-io-9.4.19.v20190610.jar\n",
      "Downloading https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-io/9.4.19.v20190610/jetty-io-9.4.19.v20190610.jar.sha1\n",
      "Downloading https://repo1.maven.org/maven2/sh/almond/ammonite-spark_2.11/0.5.0/ammonite-spark_2.11-0.5.0.jar\n",
      "Downloaded https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-util/9.4.19.v20190610/jetty-util-9.4.19.v20190610.jar.sha1\n",
      "Downloading https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-util/9.4.19.v20190610/jetty-util-9.4.19.v20190610.jar\n",
      "Downloaded https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-io/9.4.19.v20190610/jetty-io-9.4.19.v20190610.jar.sha1\n",
      "Downloading https://repo1.maven.org/maven2/sh/almond/ammonite-spark_2.11/0.5.0/ammonite-spark_2.11-0.5.0.jar.sha1\n",
      "Downloading https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-http/9.4.19.v20190610/jetty-http-9.4.19.v20190610.jar\n",
      "Downloaded https://repo1.maven.org/maven2/sh/almond/ammonite-spark_2.11/0.5.0/ammonite-spark_2.11-0.5.0.jar.sha1\n",
      "Downloading https://repo1.maven.org/maven2/sh/almond/almond-spark_2.11/0.6.0/almond-spark_2.11-0.6.0.jar\n",
      "Downloaded https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-io/9.4.19.v20190610/jetty-io-9.4.19.v20190610.jar\n",
      "Downloading https://repo1.maven.org/maven2/sh/almond/almond-spark_2.11/0.6.0/almond-spark_2.11-0.6.0.jar.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/sh/almond/almond-spark_2.11/0.6.0/almond-spark_2.11-0.6.0.jar.sha1\n",
      "Downloading https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-http/9.4.19.v20190610/jetty-http-9.4.19.v20190610.jar.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/sh/almond/almond-spark_2.11/0.6.0/almond-spark_2.11-0.6.0.jar\n",
      "Downloading https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-util/9.4.19.v20190610/jetty-util-9.4.19.v20190610-sources.jar\n",
      "Downloaded https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-http/9.4.19.v20190610/jetty-http-9.4.19.v20190610.jar.sha1\n",
      "Downloading https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-util/9.4.19.v20190610/jetty-util-9.4.19.v20190610-sources.jar.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/sh/almond/ammonite-spark_2.11/0.5.0/ammonite-spark_2.11-0.5.0.jar\n",
      "Downloading https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-io/9.4.19.v20190610/jetty-io-9.4.19.v20190610-sources.jar\n",
      "Downloaded https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-util/9.4.19.v20190610/jetty-util-9.4.19.v20190610-sources.jar.sha1\n",
      "Downloading https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-io/9.4.19.v20190610/jetty-io-9.4.19.v20190610-sources.jar.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-http/9.4.19.v20190610/jetty-http-9.4.19.v20190610.jar\n",
      "Downloading https://repo1.maven.org/maven2/sh/almond/ammonite-spark_2.11/0.5.0/ammonite-spark_2.11-0.5.0-sources.jar.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-io/9.4.19.v20190610/jetty-io-9.4.19.v20190610-sources.jar\n",
      "Downloading https://repo1.maven.org/maven2/sh/almond/ammonite-spark_2.11/0.5.0/ammonite-spark_2.11-0.5.0-sources.jar\n",
      "Downloaded https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-io/9.4.19.v20190610/jetty-io-9.4.19.v20190610-sources.jar.sha1\n",
      "Downloading https://repo1.maven.org/maven2/sh/almond/almond-spark_2.11/0.6.0/almond-spark_2.11-0.6.0-sources.jar.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/sh/almond/ammonite-spark_2.11/0.5.0/ammonite-spark_2.11-0.5.0-sources.jar.sha1\n",
      "Downloading https://repo1.maven.org/maven2/sh/almond/almond-spark_2.11/0.6.0/almond-spark_2.11-0.6.0-sources.jar\n",
      "Downloaded https://repo1.maven.org/maven2/sh/almond/almond-spark_2.11/0.6.0/almond-spark_2.11-0.6.0-sources.jar.sha1\n",
      "Downloading https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-server/9.4.19.v20190610/jetty-server-9.4.19.v20190610-sources.jar\n",
      "Downloaded https://repo1.maven.org/maven2/sh/almond/ammonite-spark_2.11/0.5.0/ammonite-spark_2.11-0.5.0-sources.jar\n",
      "Downloading https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-server/9.4.19.v20190610/jetty-server-9.4.19.v20190610-sources.jar.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/sh/almond/almond-spark_2.11/0.6.0/almond-spark_2.11-0.6.0-sources.jar\n",
      "Downloading https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-http/9.4.19.v20190610/jetty-http-9.4.19.v20190610-sources.jar.sha1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloaded https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-server/9.4.19.v20190610/jetty-server-9.4.19.v20190610-sources.jar.sha1\n",
      "Downloading https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-http/9.4.19.v20190610/jetty-http-9.4.19.v20190610-sources.jar\n",
      "Downloaded https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-util/9.4.19.v20190610/jetty-util-9.4.19.v20190610-sources.jar\n",
      "Downloaded https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-server/9.4.19.v20190610/jetty-server-9.4.19.v20190610.jar\n",
      "Downloaded https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-http/9.4.19.v20190610/jetty-http-9.4.19.v20190610-sources.jar.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-util/9.4.19.v20190610/jetty-util-9.4.19.v20190610.jar\n",
      "Downloaded https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-server/9.4.19.v20190610/jetty-server-9.4.19.v20190610-sources.jar\n",
      "Downloaded https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-http/9.4.19.v20190610/jetty-http-9.4.19.v20190610-sources.jar\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                   // Or use any other 2.x version here\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                               // Added automatically on importing Spark\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql._\u001b[39m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.apache.spark::spark-sql:2.3.1` // Or use any other 2.x version here\n",
    "import $ivy.`sh.almond::almond-spark:0.6.0` // Added automatically on importing Spark\n",
    "\n",
    "import org.apache.spark.sql._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually you want to disable logging in order to avoid polluting your cell outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.log4j.{Level, Logger}\n",
       "\u001b[39m"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.log4j.{Level, Logger}\n",
    "Logger.getLogger(\"org\").setLevel(Level.OFF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then create a `SparkSession` using the `NotebookSparkSessionBuilder` provided by *almond-spark*.\n",
    "\n",
    "## Running in local mode\n",
    "This will run Spark in the same JVM as your kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading spark-stubs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://repo1.maven.org/maven2/sh/almond/spark-stubs_20_2.11/0.5.0/spark-stubs_20_2.11-0.5.0.pom\n",
      "Downloading https://repo1.maven.org/maven2/sh/almond/spark-stubs_20_2.11/0.5.0/spark-stubs_20_2.11-0.5.0.pom.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/sh/almond/spark-stubs_20_2.11/0.5.0/spark-stubs_20_2.11-0.5.0.pom\n",
      "Downloaded https://repo1.maven.org/maven2/sh/almond/spark-stubs_20_2.11/0.5.0/spark-stubs_20_2.11-0.5.0.pom.sha1\n",
      "Downloading https://repo1.maven.org/maven2/sh/almond/spark-stubs_20_2.11/0.5.0/spark-stubs_20_2.11-0.5.0-sources.jar\n",
      "Downloading https://repo1.maven.org/maven2/sh/almond/spark-stubs_20_2.11/0.5.0/spark-stubs_20_2.11-0.5.0-sources.jar.sha1\n",
      "Downloading https://repo1.maven.org/maven2/sh/almond/spark-stubs_20_2.11/0.5.0/spark-stubs_20_2.11-0.5.0.jar\n",
      "Downloading https://repo1.maven.org/maven2/sh/almond/spark-stubs_20_2.11/0.5.0/spark-stubs_20_2.11-0.5.0.jar.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/sh/almond/spark-stubs_20_2.11/0.5.0/spark-stubs_20_2.11-0.5.0-sources.jar\n",
      "Downloaded https://repo1.maven.org/maven2/sh/almond/spark-stubs_20_2.11/0.5.0/spark-stubs_20_2.11-0.5.0-sources.jar.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/sh/almond/spark-stubs_20_2.11/0.5.0/spark-stubs_20_2.11-0.5.0.jar\n",
      "Downloaded https://repo1.maven.org/maven2/sh/almond/spark-stubs_20_2.11/0.5.0/spark-stubs_20_2.11-0.5.0.jar.sha1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting spark JARs\n",
      "Creating SparkSession\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href=\"http://0a3a93d19243:4040\">Spark UI</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mspark\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@737acd6f"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = {\n",
    "  NotebookSparkSession\n",
    "    .builder()\n",
    "    .master(\"local[*]\")\n",
    "    .getOrCreate()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a `SparkSession`, we can get a `SparkContext` from it run Spark calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36msc\u001b[39m"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sc = spark\n",
    "    .sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then create an `RDD` and run some calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mrdd\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32mrdd\u001b[39m.\u001b[32mRDD\u001b[39m[\u001b[32mInt\u001b[39m] = ParallelCollectionRDD[0] at parallelize at cmd6.sc:1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rdd = sc\n",
    "    .parallelize(1 to 100000000, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "var comm = Jupyter.notebook.kernel.comm_manager.new_comm('cancel-stage-de718150-c729-419c-b7dc-d5fcd0fb4233', {});\n",
       "\n",
       "function cancelStage(stageId) {\n",
       "  console.log('Cancelling stage ' + stageId);\n",
       "  comm.send({ 'stageId': stageId });\n",
       "}\n",
       "</script>\n",
       "          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">sum at cmd7.sc:1</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    100 / 100\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mn\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m5.00000015E15\u001b[39m"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val n = rdd\n",
    "    .map(_ + 1)\n",
    "    .sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you execute a Spark action like `sum` you should see a progress bar, showing the progress of the running Spark job. If you're using the Jupyter classic UI, you can also click on *(kill)* to cancel the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">map at cmd8.sc:1</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    100 / 100\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">collect at cmd8.sc:1</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    100 / 100\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mn\u001b[39m: \u001b[32mArray\u001b[39m[(\u001b[32mInt\u001b[39m, \u001b[32mInt\u001b[39m)] = \u001b[33mArray\u001b[39m(\n",
       "  (\u001b[32m0\u001b[39m, \u001b[32m1432236160\u001b[39m),\n",
       "  (\u001b[32m1\u001b[39m, \u001b[32m1342236160\u001b[39m),\n",
       "  (\u001b[32m2\u001b[39m, \u001b[32m1352236160\u001b[39m),\n",
       "  (\u001b[32m3\u001b[39m, \u001b[32m1362236160\u001b[39m),\n",
       "  (\u001b[32m4\u001b[39m, \u001b[32m1372236160\u001b[39m),\n",
       "  (\u001b[32m5\u001b[39m, \u001b[32m1382236160\u001b[39m),\n",
       "  (\u001b[32m6\u001b[39m, \u001b[32m1392236160\u001b[39m),\n",
       "  (\u001b[32m7\u001b[39m, \u001b[32m1402236160\u001b[39m),\n",
       "  (\u001b[32m8\u001b[39m, \u001b[32m1412236160\u001b[39m),\n",
       "  (\u001b[32m9\u001b[39m, \u001b[32m1422236160\u001b[39m)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val n = rdd\n",
    "    .map(n => \n",
    "        (n % 10, n)\n",
    "    )\n",
    "    .reduceByKey(_ + _)\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syncing Dependencies\n",
    "\n",
    "If extra dependencies are loaded, via ``import $ivy.`â€¦` `` after the `SparkSession` has been created, you should call `NotebookSparkSession.sync()` for the newly added JARs to be passed to the Spark executors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://repo1.maven.org/maven2/org/typelevel/cats-core_2.11/1.6.0/cats-core_2.11-1.6.0.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/typelevel/cats-core_2.11/1.6.0/cats-core_2.11-1.6.0.pom.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/org/typelevel/cats-core_2.11/1.6.0/cats-core_2.11-1.6.0.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/typelevel/cats-core_2.11/1.6.0/cats-core_2.11-1.6.0.pom.sha1\n",
      "Downloading https://repo1.maven.org/maven2/org/typelevel/cats-kernel_2.11/1.6.0/cats-kernel_2.11-1.6.0.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/typelevel/cats-macros_2.11/1.6.0/cats-macros_2.11-1.6.0.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/typelevel/machinist_2.11/0.6.6/machinist_2.11-0.6.6.pom\n",
      "Downloading https://repo1.maven.org/maven2/org/typelevel/cats-kernel_2.11/1.6.0/cats-kernel_2.11-1.6.0.pom.sha1\n",
      "Downloading https://repo1.maven.org/maven2/org/typelevel/machinist_2.11/0.6.6/machinist_2.11-0.6.6.pom.sha1\n",
      "Downloading https://repo1.maven.org/maven2/org/typelevel/cats-macros_2.11/1.6.0/cats-macros_2.11-1.6.0.pom.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/org/typelevel/cats-kernel_2.11/1.6.0/cats-kernel_2.11-1.6.0.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/typelevel/cats-kernel_2.11/1.6.0/cats-kernel_2.11-1.6.0.pom.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/org/typelevel/cats-macros_2.11/1.6.0/cats-macros_2.11-1.6.0.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/typelevel/machinist_2.11/0.6.6/machinist_2.11-0.6.6.pom.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/org/typelevel/machinist_2.11/0.6.6/machinist_2.11-0.6.6.pom\n",
      "Downloaded https://repo1.maven.org/maven2/org/typelevel/cats-macros_2.11/1.6.0/cats-macros_2.11-1.6.0.pom.sha1\n",
      "Downloading https://repo1.maven.org/maven2/org/typelevel/machinist_2.11/0.6.6/machinist_2.11-0.6.6.jar\n",
      "Downloading https://repo1.maven.org/maven2/org/typelevel/machinist_2.11/0.6.6/machinist_2.11-0.6.6.jar.sha1\n",
      "Downloading https://repo1.maven.org/maven2/org/typelevel/cats-core_2.11/1.6.0/cats-core_2.11-1.6.0.jar\n",
      "Downloading https://repo1.maven.org/maven2/org/typelevel/cats-core_2.11/1.6.0/cats-core_2.11-1.6.0.jar.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/org/typelevel/cats-core_2.11/1.6.0/cats-core_2.11-1.6.0.jar.sha1\n",
      "Downloading https://repo1.maven.org/maven2/org/typelevel/cats-macros_2.11/1.6.0/cats-macros_2.11-1.6.0.jar\n",
      "Downloaded https://repo1.maven.org/maven2/org/typelevel/machinist_2.11/0.6.6/machinist_2.11-0.6.6.jar.sha1\n",
      "Downloading https://repo1.maven.org/maven2/org/typelevel/cats-macros_2.11/1.6.0/cats-macros_2.11-1.6.0.jar.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/org/typelevel/machinist_2.11/0.6.6/machinist_2.11-0.6.6.jar\n",
      "Downloading https://repo1.maven.org/maven2/org/typelevel/cats-kernel_2.11/1.6.0/cats-kernel_2.11-1.6.0-sources.jar\n",
      "Downloaded https://repo1.maven.org/maven2/org/typelevel/cats-macros_2.11/1.6.0/cats-macros_2.11-1.6.0.jar\n",
      "Downloading https://repo1.maven.org/maven2/org/typelevel/cats-kernel_2.11/1.6.0/cats-kernel_2.11-1.6.0-sources.jar.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/org/typelevel/cats-macros_2.11/1.6.0/cats-macros_2.11-1.6.0.jar.sha1\n",
      "Downloading https://repo1.maven.org/maven2/org/typelevel/cats-macros_2.11/1.6.0/cats-macros_2.11-1.6.0-sources.jar\n",
      "Downloading https://repo1.maven.org/maven2/org/typelevel/cats-macros_2.11/1.6.0/cats-macros_2.11-1.6.0-sources.jar.sha1\n",
      "Downloading https://repo1.maven.org/maven2/org/typelevel/cats-kernel_2.11/1.6.0/cats-kernel_2.11-1.6.0.jar\n",
      "Downloaded https://repo1.maven.org/maven2/org/typelevel/cats-kernel_2.11/1.6.0/cats-kernel_2.11-1.6.0-sources.jar.sha1\n",
      "Downloading https://repo1.maven.org/maven2/org/typelevel/cats-kernel_2.11/1.6.0/cats-kernel_2.11-1.6.0.jar.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/org/typelevel/cats-macros_2.11/1.6.0/cats-macros_2.11-1.6.0-sources.jar\n",
      "Downloading https://repo1.maven.org/maven2/org/typelevel/cats-core_2.11/1.6.0/cats-core_2.11-1.6.0-sources.jar\n",
      "Downloaded https://repo1.maven.org/maven2/org/typelevel/cats-kernel_2.11/1.6.0/cats-kernel_2.11-1.6.0-sources.jar\n",
      "Downloading https://repo1.maven.org/maven2/org/typelevel/cats-core_2.11/1.6.0/cats-core_2.11-1.6.0-sources.jar.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/org/typelevel/cats-macros_2.11/1.6.0/cats-macros_2.11-1.6.0-sources.jar.sha1\n",
      "Downloading https://repo1.maven.org/maven2/org/typelevel/machinist_2.11/0.6.6/machinist_2.11-0.6.6-sources.jar\n",
      "Downloaded https://repo1.maven.org/maven2/org/typelevel/cats-kernel_2.11/1.6.0/cats-kernel_2.11-1.6.0.jar.sha1\n",
      "Downloading https://repo1.maven.org/maven2/org/typelevel/machinist_2.11/0.6.6/machinist_2.11-0.6.6-sources.jar.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/org/typelevel/machinist_2.11/0.6.6/machinist_2.11-0.6.6-sources.jar\n",
      "Downloaded https://repo1.maven.org/maven2/org/typelevel/machinist_2.11/0.6.6/machinist_2.11-0.6.6-sources.jar.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/org/typelevel/cats-core_2.11/1.6.0/cats-core_2.11-1.6.0-sources.jar.sha1\n",
      "Downloaded https://repo1.maven.org/maven2/org/typelevel/cats-core_2.11/1.6.0/cats-core_2.11-1.6.0-sources.jar\n",
      "Downloaded https://repo1.maven.org/maven2/org/typelevel/cats-core_2.11/1.6.0/cats-core_2.11-1.6.0.jar\n",
      "Downloaded https://repo1.maven.org/maven2/org/typelevel/cats-kernel_2.11/1.6.0/cats-kernel_2.11-1.6.0.jar\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                               \n",
       "\n",
       "\u001b[39m\n",
       "\u001b[36mres9_1\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@737acd6f"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.typelevel::cats-core:1.6.0`\n",
    "\n",
    "NotebookSparkSession.sync() // cats should be available on workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets and Dataframes\n",
    "\n",
    "If you try to create a `Dataset` or a `Dataframe` from some data structure containing a case class and you're getting an `org.apache.spark.sql.AnalysisException: Unable to generate an encoder for inner class ...` when calling `.toDS`/`.toDF`, try the following workaround:\n",
    "\n",
    "Add `org.apache.spark.sql.catalyst.encoders.OuterScopes.addOuterScope(this)` in the same cell where you define case classes involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mspark.implicits._\n",
       "\n",
       "\u001b[39m\n",
       "defined \u001b[32mclass\u001b[39m \u001b[36mPerson\u001b[39m\n",
       "\u001b[36mds\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mPerson\u001b[39m] = [id: string, value: int]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spark.implicits._\n",
    "\n",
    "org.apache.spark.sql.catalyst.encoders.OuterScopes.addOuterScope(this);\n",
    "\n",
    "case class Person(id: String, value: Int)\n",
    "\n",
    "val ds = List(\n",
    "    Person(\"Alice\", 42), \n",
    "    Person(\"Bob\", 43), \n",
    "    Person(\"Charlie\", 44)\n",
    ").toDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This workaround won't be neccessary anymore in future Spark versions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rich Display of Datasets and Dataframes\n",
    "\n",
    "As of now, *almond-spark* doesn't include native rich display capabilities for Datasets and Dataframes. So by default, we only have ascii rendering of tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|     id|value|\n",
      "+-------+-----+\n",
      "|  Alice|   42|\n",
      "|    Bob|   43|\n",
      "|Charlie|   44|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not too hard to add your own displayer though. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mRichDF\u001b[39m"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// based on a snippet by Ivan Zaitsev\n",
    "// https://github.com/almond-sh/almond/issues/180#issuecomment-364711999\n",
    "implicit class RichDF(val df: DataFrame) {\n",
    "  def showHTML(limit:Int = 20, truncate: Int = 20) = {\n",
    "    import xml.Utility.escape\n",
    "    val data = df.take(limit)\n",
    "    val header = df.schema.fieldNames.toSeq\n",
    "    val rows: Seq[Seq[String]] = data.map { row =>\n",
    "      row.toSeq.map { cell =>\n",
    "        val str = cell match {\n",
    "          case null => \"null\"\n",
    "          case binary: Array[Byte] => binary.map(\"%02X\".format(_)).mkString(\"[\", \" \", \"]\")\n",
    "          case array: Array[_] => array.mkString(\"[\", \", \", \"]\")\n",
    "          case seq: Seq[_] => seq.mkString(\"[\", \", \", \"]\")\n",
    "          case _ => cell.toString\n",
    "        }\n",
    "        if (truncate > 0 && str.length > truncate) {\n",
    "          // do not show ellipses for strings shorter than 4 characters.\n",
    "          if (truncate < 4) str.substring(0, truncate)\n",
    "          else str.substring(0, truncate - 3) + \"...\"\n",
    "        } else {\n",
    "          str\n",
    "        }\n",
    "      }: Seq[String]\n",
    "    }\n",
    "\n",
    "    publish.html(s\"\"\"\n",
    "      <table class=\"table\">\n",
    "        <tr>\n",
    "        ${header.map(h => s\"<th>${escape(h)}</th>\").mkString}\n",
    "        </tr>\n",
    "        ${rows.map { row =>\n",
    "          s\"<tr>${row.map { c => s\"<td>${escape(c)}</td>\" }.mkString}</tr>\"\n",
    "        }.mkString\n",
    "        }\n",
    "      </table>\"\"\")\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <table class=\"table\">\n",
       "        <tr>\n",
       "        <th>id</th><th>value</th>\n",
       "        </tr>\n",
       "        <tr><td>Alice</td><td>42</td></tr><tr><td>Bob</td><td>43</td></tr><tr><td>Charlie</td><td>44</td></tr>\n",
       "      </table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds.toDF.showHTML()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.11",
   "language": "scala",
   "name": "scala211"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
